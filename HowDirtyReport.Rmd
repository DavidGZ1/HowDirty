---
title: Evaluation of LC-MS contamination risk (HowDirty)
output:
  html_document:
    toc: true
    toc_float: false
    theme: united
    number_sections: TRUE
params:
  DataSet: 
    label: "Data set or experiment (keep it short since it's used as prefix for output file names)"
    value: 2022-132_FASP_filters
    input: text
  UserNames: 
    label: "User(s)"
    value: 
    input: text
  Notes:
    label:
    value:
    input: text
  PeakAreasContaminantsFile:
    label: "PeakAreaContaminants report from Skyline"
    value: data/PeakAreas_Contaminants_2023-231.csv # PeaKAreas_Contaminants report (directory/name) resulting from Skyline
  AnnotationFile:
    label: "Sample annotation file"
    value: data/samples_annotation_20223-231.csv # Samples Annotation directory/name
  RefThresholdsFile:
    label: "Reference threshold file (total)"
    value: data/contaminants_tshd_2021_E480.csv # A file directory/name in or FALSE if no threshold available
  RefThresholdsSampleLevelFile:
    label: "Reference threshold file (sample)"
    value: data/contaminants_tshd_sample_2021_E480.csv # A file directory/name or FALSE if no threshold available
  OutputDirectory:
    label: "Directory where the report and the results are exported"
    value: results
  nTopContaminantGroups:
    label: "Top n contaminant groups to show in plots"
    value: 3
    input: numeric
  MultiplyDilutionFactor:
    label:
    value: FALSE #Use carefully, normalization by TIC already takes into account slight differences in injection amounts
  PlotsInteractive: 
    label:
    value: TRUE #TRUE = interactive in html, FALSE = static
  PlotsSave:
    label:
    value: FALSE #Saves all the plots as .jpg
---

<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

# Report information

## Data set information

**Data set:** `r params$DataSet`

**User(s):** `r params$UserNames`

**Date:**  `r Sys.Date()` 

**Notes:** `r params$Notes`

**Objective:** Evaluate the risk of possible contamination with polymers and small molecules in the samples from the data set.

## HowDirty evaluation of LC-MS results

This report was generated with a prototype version of *HowDirty*. This is meant to help you evaluating *How Dirty* are your samples (or system) in LC-MS analyses. The possible contaminants reported hereby could impact the quality of the results (e.g. analyte IDs and reproducibility) and, in extreme cases, even damage the column or instruments. The raw data are previously analyzed using Skyline to extract LC-MS peaks possibly corresponding to contaminants. Then, a Risk level is assigned to each contaminant by comparing against the reference threshold (see Procedures for details). Finally, the Risk is similarly assessed at the Sample and whole Sample Set levels. These are indicative of the level of possible contamination.

**Code author:** David Gomez-Zepeda (HI-TRON)

**Version:** 0.04

```{r setup, include=FALSE, warning=FALSE}
#General parameters for knitr
require("knitr")
# opts_knit$set(root.dir = normalizePath("..")) #Set wd to folder above, currently not working
# opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
opts_chunk$set(echo = FALSE, message = TRUE, warning = FALSE)
print(getwd())
# normalizePath("..")
```

```{r verify_files, include=FALSE, echo=FALSE}
# verify that parameters were filled
if(is.null(params$PeakAreasContaminantsFile))  stop("Please enter the PeakAreasContaminantsFile")
if(is.null(params$RefThresholdsFile)) stop("Please enter the RefThresholdsFile")
if(is.null(params$ RefThresholdsSampleLevelFile)) stop("Please enter the RefThresholdsSampleLevelFile")
# verify that files exist
filenames <- unlist(params[grepl("File" , names(params))])
filenames <- filenames[filenames != "FALSE"] # ignore if FALSE (e.g. for thresholds)
filecheck <- file.exists(filenames) 
if(any(!filecheck)){
   files_missing <-     data.frame(File=names(filenames[!filecheck] ), Entry=filenames[!filecheck] , row.names=NULL)
   files_missing$message <- paste0(files_missing$File, ": ", files_missing$Entry, "\n")
   files_missing
  # files_missing <- filenames[!filecheck] %>% 
  #   data.frame(File=names(.), Entry=., row.names=NULL) %>% 
  #   mutate(message = paste0(File, ": ", Entry,"\n"))
  stop("The input files below were not found. Please verify that they are in the right location: \n ", files_missing$message)
}
```


```{r initialize, message=FALSE, include=FALSE}
#Install required packages
##Test whether all required packages, install packages needed and install if needed
required_packages <- c('ggplot2', 'ggpubr', 'scales', 'plotly',
              'openxlsx', 'mgsub', 'DT', 'shiny', 'tidyverse', 'HowDirty')
# required_packages <- c(packages)
installed_packages <- required_packages %in% installed.packages()[,"Package"]
missing_packages <- required_packages[!installed_packages]
if ( length(missing_packages) > 0 ) install.packages(packages)
##Load libraries
invisible(lapply(required_packages, require, character.only = TRUE))
# names for output files
today_date <- gsub(patt ="-", rep="",paste0(gsub(patt ="-", rep="", Sys.Date()), "_", format(Sys.time(), "%H%M")))
filedir_report <- file.path(params$OutputDirectory,
                            paste0(params$DataSet, "_report_contaminants_", today_date, ".xlsx"))
filedir_sessioninfo <- gsub(filedir_report, patt = ".xlsx", rep = "_RSessionInfo.txt", filedir_report)
if(!dir.exists(params$OutputDirectory)) dir.create(params$OutputDirectory)
# report-specific functions
print_plot_or_plotly <- function(input, height_plotly = 500, width_plotly = 1000, interactive = params$PlotsInteractive){
  # wrapper function to use ggplotly when params$PlotsInteractive == TRUE
  if(interactive == TRUE){
    ggplotly(input, height = height_plotly, width = width_plotly)
    # layout_ggplotly_label_margin( x = -0.0, y = -0.05) #fixes label margin problem
  }else{
    if(interactive == FALSE){
      print(input)
    }
  }
}
```

```{r functions2move}
plot_conta_summ_sampleset <- function(df_conta){
  df_conta %>% 
    arrange(desc(Risk)) %>% 
    mutate(ypos = cumsum(Freq) - 0.5*Freq) %>% 
    ggplot(aes(x = "", y= Freq , fill= Risk)) +
    geom_bar(stat = "identity", color = "white") +
    coord_polar("y", start=0) +
    geom_text(aes(y = ypos, label = Perc), color = "white", size=4) +
    theme_void()  +
    scale_fill_risk_level()
}
count_factor_columns <- function(df){
  df  %>% 
    summarise(across(where(is.factor), ~n_distinct(.x))) %>% 
    t() %>% 
    as.data.frame() %>% 
    rename("Count" = 1) %>% 
    rownames_to_column("Variable")
}
get_w <- function() {
  # Get the current figure width in pixels
  # solution to print ggplotly inside asis from https://stackoverflow.com/questions/61906480/how-to-display-ggplotly-plots-with-dynamically-created-tabs-and-for-loops
  
  with(knitr::opts_current$get(c("fig.width", "dpi", "fig.retina")),
       fig.width*dpi/fig.retina)
}

get_h <- function() {
    # Get the current figure height in pixels
  # solution to print ggplotly inside asis from https://stackoverflow.com/questions/61906480/how-to-display-ggplotly-plots-with-dynamically-created-tabs-and-for-loops
  with(knitr::opts_current$get(c("fig.height", "dpi", "fig.retina")),
       fig.height*dpi/fig.retina)
}

summarize_conta <- function(df_conta, ...){
  #summarize results by ...
  output <-
  df_conta %>%
  group_by(...) %>% 
  summarise(across(c(Abundance),
                   list(min = ~min(.x, na.rm = TRUE),
                        quantile25 = ~quantile(.x, na.rm = TRUE)[2],
                        median = ~median(.x, na.rm = TRUE),
                        quantile75 = ~quantile(.x, na.rm = TRUE)[4],
                        max = ~max(.x, na.rm = TRUE),
                        total = ~sum(.x, na.rm = TRUE))),
            .groups = "drop") %>% 
  mutate(across(where(is.numeric), ~signif(.x, 4)))
  return(output)
}
arrange_analytegroup_levels <- function(df_conta, metric = "median"){
  #arrange column AnalyteGroup based on metric
  # metric = min, median, max, total
  if(metric %in% c("min", "median", "max", "total")){
    variable <-  paste0("Abundance_", metric)
  }else{
    stop("metric must be any of the following: = min, median, max, total")
  }
  analytegroup_arranged <- 
    df_conta %>% 
    summarize_conta(., AnalyteGroup) %>% 
    arrange(desc(get(variable))) %>% 
    pull(AnalyteGroup) %>% 
    as.character()
  output <- df_conta %>% 
    mutate(AnalyteGroup = factor(AnalyteGroup, analytegroup_arranged))
  return(output)
}
```

```{r functions_in_progress}

```

```{r rawr_ggsave}
# Other functions
# rawr_ggsave <-function(input, file, width = 20, height = 24) {
#   ggsave(file.path("4_figures", paste0(file, ".tiff")) , input, device =  "tiff", 
#          scale = 1, width = width, height = height, units = "cm")
# }
```

# Procedure

## Data analysis

* Raw data was imported into Skyline to extract the features corresponding to possible contaminants (ToDo: add references)
* For this purpose, the Molecular Contaminant List template was used (Gomez-Zepeda *et al.*, 2023; modified from Rardin, 2018)
* The feature area of extracted ion chromatograms was processed using *HowDirty* to generate this report (Gomez-Zepeda *et al.*, 2023)

## Warning

The algorithm used for peak picking in Skyline is simple and based only on m/z and charge (z). Thus, some true analyte peaks (e.g. peptides) could be incorrectly assigned to contaminants (i.e. false positives). Therefore, it is recommended to also look into the Skyline file to evaluate other factors, such as patterns of contaminant groups elution across the retention time.

## Calculations within *HowDirty*

* TICA = Total Ion Current Area
* Abundance (Normalized abundance) = TotalAreaMS1 / TICA
* TotalAbundance_ContaminantGroup = Sum (Abundance_ContaminantGroup) across all the contaminants in one ContaminantGroup for one sample
* TotalAbundance = Sum (Abundance) across all the contaminants for one sample
* Contaminant-specific Risk level assessment was performed by comparing the Abundance of the possible contaminants in each one of the test samples (current data set) against thresholds previously extrapolated from a reference data set (~ 1000s runs). These thresholds are reported in `r filedir_report`--> ref_conta_tshd
* Sample level summary contaminant group assessment was performed by comparing the TotalAbundance_ContaminantGroup against the summed thresholds from each contaminant
* Sample level summary contaminant risk assessment was performed by comparing the TotalAbundance against the sample-level quantile thresholds from the reference dataset
* These thresholds are reported in `r filedir_report`--> ref_conta_tshd_sample

# Input

```{r read_data}
# Load thresholds
if(params$RefThresholdsFile == FALSE){
  # set arbitrary thresholds
  ref_conta_tshd <- get_simple_thresholds_analyte(conta_raw)
  ref_conta_tshd_sample <- get_simple_thresholds_sample()
  message("WARNING: Reference Threshold File was not provided. Thus, threshold were set at the same level for all the contaminants")
} else{ 
  # read thresholds from file
  ref_conta_tshd <- read.csv(params$RefThresholdsFile) %>% 
    select(-any_of("X"))
  ref_conta_tshd_sample <- read.csv(params$RefThresholdsSampleLevelFile) %>% 
    select(-any_of("X"))
}
# read files
## Skyline results of contaminant peak area and height
conta_raw <- read_conta_results(file_report_skyline = params$PeakAreasContaminantsFile, simplify_AnalyteGroup = TRUE)
## information about samples (annotation)
samples_annot <- read_samples_annotation(params$AnnotationFile) 
## check if all samples are included in both results and annotation file
check_samples_in_results(conta_raw, samples_annot)
```

```{r annotate_results}
# Annotate contamination results with samples_annot, multiply by dilution_factor, assign risk level
conta <- conta_raw %>% 
  annotate_conta_samples(., samples_annot, # Annotate with samples_annot, multiply by dilution_factor
                         remove_missing = TRUE, 
                         multiply_dilution_factor = params$MultiplyDilutionFactor) %>% 
  annotate_conta_thresholds(., ref_conta_tshd)  %>%  # assign RiskLevel
  arrange_analytegroup_levels(metric = "median") # arrange analyte group levels based on overall median abundance
```

The data set contained the following:

```{r summary_input}
options(width = 1000)
count_factor_columns(conta) %>% 
  filter(!Variable %in% c("Risk", "RiskLevel")) %>% 
  mutate(Variable = paste0(Variable, "s")) %>% 
  kable("html")
```


```{r summaries}
#Summary of thresholds for each contaminant group
ref_conta_tshd_sum <-  ref_conta_tshd %>% 
  group_by(AnalyteGroup) %>% 
  summarise(across(starts_with("Tshd"), sum), .groups = "drop")

## Summary by Analyte Group, needed to get top groups
conta_summ_analytegroup <- summarize_conta(conta, AnalyteGroup)
conta_summ_analyte <- summarize_conta(conta, AnalyteGroup, Analyte)

## top contaminants
# analytegroups_area_ordered <- 
#   conta_summ_analytegroup %>% 
#   select(AnalyteGroup, Abundance_median) %>% 
#   unique() %>% 
#   arrange(desc(Abundance_median))

## Sample level
conta_summ_sample <-
  conta %>%
  group_by(Condition, Sample, ReplicateName) %>%
  summarise(TotalAbundance = round(sum(Abundance, na.rm=TRUE), 4), .groups = "drop") %>%
  mutate(Risk =
           cut(x = TotalAbundance,
               breaks = ref_conta_tshd_sample$Break,
               labels = ref_conta_tshd_sample$Labels[-1]))  %>%
  drop_na %>%
  mutate(RiskLevel= as.numeric(substr(as.character(Risk),1,1)),
         RiskLevel = factor(RiskLevel, levels = c(0:6))) %>%
  relocate(Condition, Sample, ReplicateName, TotalAbundance, RiskLevel, Risk) %>%
  # Join with median from top 8 contaminants
  full_join(.,
            conta %>%
              # filter(AnalyteGroup %in% top_analytegroups_area$AnalyteGroup) %>%
              pivot_wider(id_cols = ReplicateName, names_from = AnalyteGroup, names_prefix = "TotalAbundance_",
                          values_from = Abundance, values_fn = function(x) sum(x, na.rm=TRUE)),
            by = "ReplicateName")
conta_summ_condition <- summarize_conta(conta, Condition, AnalyteGroup, Analyte)
  

#Summary (sum) of contaminants
conta_summ_sample_risk <-
  conta_summ_sample %>%
  select(-TotalAbundance) %>%
    # rename(TotalAbundance_Total = TotalAbundance) %>%
  select(Condition, Sample, starts_with("TotalAbundance_")) %>%
  pivot_longer(cols = starts_with("Total"),
               names_to = "AnalyteGroup",
               names_prefix = "TotalAbundance_",
               values_to = "Abundance_median") %>%
  left_join(., ref_conta_tshd_sum,  by = "AnalyteGroup") %>%
  mutate(RiskLevel = case_when(Abundance_median ==0 ~ 0,
                               Abundance_median < Tshd_Area_TICA_perc25 ~ 1,
                               (Tshd_Area_TICA_perc25 <= Abundance_median & Abundance_median < Tshd_Area_TICA_perc50) ~ 2,
                               (Tshd_Area_TICA_perc50 <= Abundance_median & Abundance_median < Tshd_Area_TICA_perc75) ~ 3,
                               (Tshd_Area_TICA_perc75 <= Abundance_median & Abundance_median < Tshd_Area_TICA_perc90) ~ 4,
                               (Tshd_Area_TICA_perc90 <= Abundance_median) ~ 5,
                               TRUE ~ 6),
         Risk = mgsub(RiskLevel, patt=c(0, 1, 2, 3, 4, 5, 6) ,
                      rep = c("0) Not Detected", "1) Very Low", "2) Low", "3) Medium", "4) High", "5) Very High", "6) No threshold in reference"))) %>%
  mutate(Risk = as.factor(Risk),
         RiskLevel = as.factor(RiskLevel),
         # AnalyteGroup = factor(AnalyteGroup, levels = rev(analytegroups_area_ordered$AnalyteGroup)), # order from lowest to highest Abundance_median  (shown inversed in plot)
         Sample = Sample) %>%
  select(-starts_with("Tshd_"))

#Dataset level
conta_summ_sampleset <-
  conta_summ_sample %>%
  count(Risk, name = "Count") %>%
  mutate(Fraction = paste0(Count, "/", sum(Count)) ,
         Freq =  round(Count/sum(Count), 2),
         Perc = label_percent()(Freq),
         Tag = paste0(Risk, ": ", Perc, " (", Fraction, ")")) 
conta_summ_sampleset_verbose <- 
  conta_summ_sampleset %>% 
  summarise(Risk  =  paste0(Tag, collapse = "; "), .groups = "drop")
# Verbose summary of the data set
max_risklevel <- max(as.numeric(conta_summ_sample$RiskLevel))
summ_msg_options <- c("Something may be wrong, all Abundances were = 0"  ,
                      "You don't like getting soappy, your samples are super clean!",
                      "You are clean to go!",
                      "Be careful, you have some medium dirty samples",
                      "WARNING: You have some dirty samples!",
                      "WARNING: You have some very dirty samples!!!")
summ_msg <- summ_msg_options[max_risklevel]
summ_color_scale <- scales::viridis_pal(end=0.8, option =  "plasma", direction = 1)(7)
summ_color <- summ_color_scale[max_risklevel]

conta_summ_analytegroup_sample <-
  summarize_conta(conta, Condition, Sample, ReplicateName, AnalyteGroup)
```

# Summary risk evaluation (total contamination) {.tabset}

* Overall status:  `r colorize_text(summ_msg, summ_color)`
* Evaluation based on the total contaminant abundance

## Global

* The piechart below shows the percentages of samples associated to each risk level
* The results were exported to `r filedir_report` --> conta_summ_sampleset

```{r plot_conta_summ_sampleset, fig.width= 4, fig.height=4}
plot_pie_conta_summ_sampleset <- plot_conta_summ_sampleset(conta_summ_sampleset)
plot_pie_conta_summ_sampleset
```

## Condition {.tabset}


## Sample {.tabset}

* The table can also be found in `r filedir_report` --> conta_summ_sample.
* RiskLevel = "1) Very Low (OK)", "2) Low (OK)", "3) Medium (Warning)", "4) High (Warning)", "5) Very High (DO NOT PROCEED)", "6) No threshold in reference"

### Dotplot by abundance

```{r plot_conta_summ_sample_risk_byabundance , echo=FALSE, warning=FALSE, fig.width= 5, fig.height=10}
dot_plot_sample_risk_total_byabundance <- 
  plot_sample_risk_total(conta_summ_sample, order_x = "Abundance") 
print_plot_or_plotly(dot_plot_sample_risk_total_byabundance)
```

### Dotplot by sample

```{r plot_conta_summ_sample_risk_bysample, echo=FALSE, warning=FALSE}
dot_plot_sample_risk_total_bysample <-
  plot_sample_risk_total(conta_summ_sample, order_x = "Sample") +
  facet_wrap(~Condition, scales = "free_x")
print_plot_or_plotly(dot_plot_sample_risk_total_bysample)
```

### Table

```{r echo=FALSE, warning=FALSE}
conta_summ_sample %>% 
  select(Condition, Sample, ReplicateName, TotalAbundance, RiskLevel) %>% 
  rename_with(~gsub(patt = "TotalAbundance_", rep = "", .x)) %>% 
  datatable(filter = 'top', options = list(
    pageLength = 10, autoWidth = TRUE))  %>% 
  formatStyle('RiskLevel',
              backgroundColor = styleEqual(c(0:6),c(scales::viridis_pal(end=0.8, option =  "plasma", direction = 1)(7))),
              backgroundSize = '50% 0%',
              backgroundRepeat = 'no-repeat',
              backgroundPosition = 'left')

```

# Contaminant group (median(Abundance)){.tabset}

* y axis is ordered from highest to lowest abundance

## Condition{.tabset}

### dotplot

```{r plot_AnalyteGroupCondition, echo=FALSE}
#dotplot
## AnalyteGroup 
dot_plot_conta_summ_condition_risk_analytegroup <- 
  plot_condition_risk_analyte(conta_summ_sample_risk,
                              order_x = "Condition", order_y = "Abundance", show_zeros = FALSE)

print_plot_or_plotly(dot_plot_conta_summ_condition_risk_analytegroup)
```

### boxplot

```{r}
#ToDo: add risk to conta_summ_analytegroup_sample, add color to plot
plot_abundance_analytegroup <- function(input_conta, x, variable,  scale = "linear"){
  # plot the abundance
  # scale: changes the scale to linear or log10; options = c("linear", "log10")
  output <-
    ggplot(input_conta, aes(y = AnalyteGroup, x = {{x}})) +
    geom_boxplot( alpha = 0.4, width = 0.5, size = 0.2, outlier.shape = NA, outlier.size = 0, outlier.alpha = 0, outlier.color = NA, outlier.fill = NA) +
    geom_point(aes(text = paste0(deparse(substitute(variable)), ": ", {{variable}})) , alpha = 0.5, size = 1) +
    # geom_point(aes(color=Risk, text = paste("Replicate: ", ReplicateName, "\nSample: ", Sample)) , alpha = 0.5, size = 1) +
    scale_color_risk(verbose = TRUE) +
    scale_x_continuous(n.breaks = 10) +
    scale_y_discrete(limits=rev) +
    xlab(gsub("_", " ", deparse(substitute(x)))) +
    ylab("Contaminant")+
    theme_hd +
    ggtitle("Abundance of contaminants") 
  
  if(scale == "linear"){return(output)}
  if(scale == "log10"){
    output <- output +
      scale_y_log10(n.breaks = 5) +
      ylab("Abundance = log10(Area/TICA)")
    return(output)}
}
```

```{r plot_bp_abundance_analytegroup_condition}
plot_bp_abundance_analytegroup_condition <-
  plot_abundance_analytegroup(conta_summ_condition,
                              x = Abundance_median,
                              variable = Condition)
# print_plot_or_plotly(plot_bp_abundance_analytegroup_condition) #not working #ToDo: fix interactive
plot_bp_abundance_analytegroup_condition

```

## Sample {.tabset}

### dotplot by abundance

```{r plot_AnalyteGroupSample_abundance, fig.height=8, fig.width=8, }
#dotplot
## AnalyteGroup 
dot_plot_conta_summ_sample_risk_analytegroup <-
  conta_summ_sample_risk %>% 
  plot_sample_risk_analyte(order_x = "Sample", order_y = "Abundance", show_zeros = FALSE)

if(params$PlotsInteractive == TRUE){
  ggplotly(dot_plot_conta_summ_sample_risk_analytegroup,
           height = 600, width = 1000)
  # layout_ggplotly_label_margin( x = -0.0, y = -0.05) #fixes label margin problem
}else{
  if(params$PlotsInteractive == FALSE){
    dot_plot_conta_summ_sample_risk_analytegroup
  }
}



```


```{r plot_bp_abundance_analytegroup_sample}
plot_bp_abundance_analytegroup_sample <-
  plot_abundance_analytegroup(conta_summ_sample_risk,
                              x = Abundance_median,
                              variable = Condition)
# print_plot_or_plotly(plot_bp_abundance_analytegroup_condition) #not working
plot_bp_abundance_analytegroup_sample

```

### boxplot

# Contaminants per sample{.tabset}

* A summary of the Abundance per AnalyteGroup was calculated and is reported in the annexed report (`r filedir_report` --> conta_summ_analytegroup).
* The Abundance of the contaminants are reported in the plots below for all the samples in the data set.
* The Pseudochromatograms represent the Abundance in function of the RentetionTime (Apex of the peak). Those can be useful to evaluate the presence of the usual patterns of polymers, i.e. from small to larger molecules; as well as the reproducibility of the RentetionTime across replicates.

## Normalized abundance{.tabset}

```{r plot_AnalyteGroupArea, results='asis', fig.height=6, fig.width=10, warning=FALSE}
plot_abundance_analytegroup_list <-
  lapply(levels(conta$AnalyteGroup)[c(1:params$nTopContaminantGroups)],
         function(x){
           plot_abundance(filter(conta, AnalyteGroup == x)) %>% 
             ggplotly(width = get_w(), height = get_h()) %>% 
             htmltools::tagList()
         }
  )
names(plot_abundance_analytegroup_list) <-
  levels(conta$AnalyteGroup)[c(1:params$nTopContaminantGroups)]

for (i in 1:length(plot_abundance_analytegroup_list)) {
  cat("### ", names(plot_abundance_analytegroup_list)[i],"\n")
  if(params$PlotsInteractive == TRUE){
    print(htmltools::tagList(plot_abundance_analytegroup_list[[i]])) #required to print ggplotly inside asis
  }else{if(params$PlotsInteractive == FALSE){
    plot_abundance_analytegroup_list[[i]]
  }
  }
  cat('\n\n')
}
```

## Pseudochromatograms (Abundance vs. RT){.tabset}

```{r plot_AnalyteGroupPseudoChromato, results='asis', echo=FALSE, fig.height=6, fig.width=8, warning=FALSE}
plot_seudochromatogram_analytegroup_list <-
  lapply(levels(conta$AnalyteGroup)[c(1:params$nTopContaminantGroups)],
         function(x){
           plot_pseudochromatogram(filter(conta, AnalyteGroup == x)) %>% 
             ggplotly(width = get_w(), height = get_h()) %>% 
             htmltools::tagList()
         }
  )
names(plot_seudochromatogram_analytegroup_list) <-
  levels(conta$AnalyteGroup)[c(1:params$nTopContaminantGroups)]

for (i in 1:length(plot_seudochromatogram_analytegroup_list)) {
  cat("### ", names(plot_seudochromatogram_analytegroup_list)[i],"\n")
  if(params$PlotsInteractive == TRUE){
    print(htmltools::tagList(plot_seudochromatogram_analytegroup_list[[i]])) #required to print ggplotly inside asis
  }else{if(params$PlotsInteractive == FALSE){
    plot_seudochromatogram_analytegroup_list[[i]]
  }
  }
  cat('\n\n')
}

```


## Table

* The following table shows the results of possible contaminants detected in each sample.
* An extended version of this table containing the Area and Total-Ion-Count-Area (TICA) can also be found in `r filedir_report` --> conta.
* RiskLevel = "1) Very Low (OK)", "2) Low (OK)", "3) Medium (Warning)", "4) High (Warning)", "5) Very High (DO NOT PROCEED)", "6) No theshold in reference"

```{r table_conta, echo=FALSE, warning=FALSE}
# conta %>% 
#   select(AnalyteGroup, Analyte, Condition, Sample, ReplicateName, RiskLevel, Abundance) %>% 
#   arrange(desc(Abundance)) %>% 
#   datatable(filter = 'top', 
#             options = list(pageLength = 10, autoWidth = TRUE)) %>% 
#   formatStyle('RiskLevel',
#               backgroundColor = styleEqual(c(0, 1, 2, 3, 4, 5, 6),c(scales::viridis_pal(end=0.8, option =  "plasma", direction = 1)(7))))
```


# Appendixes

* Plots are exported in folder 4_figures.
* Result tables are exported in folder `r filedir_report`.

```{r echo=FALSE, warning=FALSE}
res_list<- list(conta=conta, 
             conta_summ_sample=conta_summ_sample,
             conta_summ_sampleset=conta_summ_sampleset,
             conta_summ_analytegroup=conta_summ_analytegroup,
             ref_conta_tshd=ref_conta_tshd,
             ref_conta_tshd_sample=ref_conta_tshd_sample)
write.xlsx(res_list,
           file = filedir_report)
writeLines(capture.output(sessionInfo()), filedir_sessioninfo)

```


# References
- Gomez-Zepeda *et al.*. HowDirty. Under preparation. (2023).
- Rardin, M. J. Rapid Assessment of Contaminants and Interferences in Mass Spectrometry Data Using Skyline. J. Am. Soc. Mass Spectrom. 29, 1327â€“1330 (2018).
